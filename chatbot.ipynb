{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506d7ce2-99be-46b6-9cdb-44a1a6e92c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.quantization import quantize_dynamic\n",
    "from torch.nn import Embedding, Linear\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2e96293-4e9d-4e48-9ae0-d0555965b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rng = random.Random()\n",
    "\n",
    "def ids_tensor(shape, vocab_size, rng=None, name=None):\n",
    "    #  Creates a random int32 tensor of the shape within the vocab size\n",
    "    if rng is None:\n",
    "        rng = global_rng\n",
    "\n",
    "    total_dims = 1\n",
    "    for dim in shape:\n",
    "        total_dims *= dim\n",
    "\n",
    "    values = []\n",
    "    for _ in range(total_dims):\n",
    "        values.append(rng.randint(0, vocab_size - 1))\n",
    "\n",
    "    return torch.tensor(data=values, dtype=torch.long, device='cpu').view(shape).contiguous()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dd0cd6c-eccf-4e66-a023-e2c2f0bbb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = ids_tensor([8, 128], 2)\n",
    "attention_mask = ids_tensor([8, 128], vocab_size=2)\n",
    "dummy_input = {\"input_ids\":input_ids, \"attention_mask\":attention_mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a481c0-0b34-4c59-a1c5-bea82253a957",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pix\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\modeling_utils.py:2168: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert all(\n",
      "C:\\Users\\pix\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\jit\\_trace.py:154: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  if a.grad is not None:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_org = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "q_model = quantize_dynamic(model_org, {Linear, Embedding})\n",
    "traced_model = torch.jit.trace(q_model, dummy_input,strict=False)\n",
    "torch.jit.save(traced_model, \"quant/pytorch_model.pth\")\n",
    "\n",
    "loaded_quantized_model = torch.jit.load( \"quant/pytorch_model.pth\")\n",
    "\n",
    "loaded_quantized_model.cpu()\n",
    "loaded_quantized_model.eval()\n",
    "\n",
    "model_org.cpu()\n",
    "model_org.eval()\n",
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45764a3c-7a28-4e2c-a3b6-552eee6cb0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a83e0881-2980-4e46-97d1-4d7afbd56e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DO_NOT_CHECK.txt\",\"r\") as f:\n",
    "    DO_NOT_CHECK = f.read()\n",
    "    DO_NOT_CHECK.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e685865d-25ed-446a-9d59-62ad4f8b02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_sentence(sentence,DO_NOT_CHECK=DO_NOT_CHECK):\n",
    "    fixed = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        word = word.lower()\n",
    "        if word in DO_NOT_CHECK:\n",
    "            fixed.append(word)\n",
    "        else:\n",
    "            suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=3, include_unknown=True)\n",
    "            fixed.append(suggestions[0].__str__().split(\",\")[0])\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d444807-c1fe-4ebf-a1d4-2388f7222b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'were can i find information about my past purchases'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(fix_sentence('Whre can I fnid informion about my past pruchases'))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5f0c6b3-a38e-433d-a0d5-0640229b410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT_TEXT</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I speak to the Human</td>\n",
       "      <td>Yes, please wait while we are connecting you t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello. How can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Hello. How can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good Morning</td>\n",
       "      <td>Hello. How can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good Afternoon</td>\n",
       "      <td>Hello. How can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greetings</td>\n",
       "      <td>Hello. How can I help you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I want to cancel my subscription</td>\n",
       "      <td>To cancel you subscription you need to go to &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I want to renew a subscription</td>\n",
       "      <td>To renew you subscription you need to go to &lt;l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How can I edit my personal details</td>\n",
       "      <td>In order to edit your personal details, please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Where can I find information on my payments</td>\n",
       "      <td>All information on past and future payemnts ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How much money do I still owe</td>\n",
       "      <td>You currently owe &lt;query&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where can I find information about my past pur...</td>\n",
       "      <td>All information on past and future payemnts ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How much does premium subscription cost</td>\n",
       "      <td>You can obtain premium subscription for $$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I want to learn more about subscription</td>\n",
       "      <td>To learn more about subscription please go to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           INPUT_TEXT  \\\n",
       "0                            Can I speak to the Human   \n",
       "1                                                  Hi   \n",
       "2                                               Hello   \n",
       "3                                        Good Morning   \n",
       "4                                      Good Afternoon   \n",
       "5                                           Greetings   \n",
       "6                    I want to cancel my subscription   \n",
       "7                     I want to renew a subscription    \n",
       "8                  How can I edit my personal details   \n",
       "9         Where can I find information on my payments   \n",
       "10                      How much money do I still owe   \n",
       "11  Where can I find information about my past pur...   \n",
       "12            How much does premium subscription cost   \n",
       "13            I want to learn more about subscription   \n",
       "\n",
       "                                             RESPONSE  \n",
       "0   Yes, please wait while we are connecting you t...  \n",
       "1                          Hello. How can I help you?  \n",
       "2                          Hello. How can I help you?  \n",
       "3                          Hello. How can I help you?  \n",
       "4                          Hello. How can I help you?  \n",
       "5                          Hello. How can I help you?  \n",
       "6   To cancel you subscription you need to go to <...  \n",
       "7   To renew you subscription you need to go to <l...  \n",
       "8   In order to edit your personal details, please...  \n",
       "9   All information on past and future payemnts ca...  \n",
       "10                          You currently owe <query>  \n",
       "11  All information on past and future payemnts ca...  \n",
       "12         You can obtain premium subscription for $$  \n",
       "13  To learn more about subscription please go to ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"input and responses.csv\", low_memory=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "decfdb88-ab79-433f-bcf9-07efc89ea402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output['token_embeddings'] \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def calculate_emb(sentence, model = loaded_quantized_model, tokenizer = tokenizer):\n",
    "    encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "    features = {'input_ids':encoded_input['input_ids'], 'attention_mask':encoded_input['attention_mask']}\n",
    "    with torch.no_grad():\n",
    "        output = model(features)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(output, encoded_input['attention_mask'])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f85e928-cc4c-4052-9517-3a913a7ab484",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_res_dicto = {}\n",
    "for inp,res in zip(data.INPUT_TEXT, data.RESPONSE):\n",
    "    inp_res_dicto.update({inp:res})\n",
    "np.save('inp_res_dicto.npy', inp_res_dicto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b7bdd8-43bb-4e85-b9ec-a1febe9fabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_emb_dicto = {}\n",
    "for i,inp in enumerate(data.INPUT_TEXT.tolist()):\n",
    "    inp_emb_dicto.update({inp:calculate_emb(inp)})\n",
    "np.save('inp_emb_dicto.npy', inp_emb_dicto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a0debc7-0eea-463c-80d6-391e142c62c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9595]]), 'Where can I find information about my past purchases')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = \" \".join(fix_sentence( 'Whre can I fnid informion about my past pruchases' ))\n",
    "embeddings1 = calculate_emb(fixed)\n",
    "best_score = 0\n",
    "best_key = None\n",
    "for key in inp_emb_dicto.keys():\n",
    "    temp_score = util.pytorch_cos_sim(embeddings1, inp_emb_dicto[key])\n",
    "    if temp_score > best_score:\n",
    "        best_key = key\n",
    "        best_score = temp_score\n",
    "best_score,best_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ac999-850e-4036-bd7d-f99e238cdea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac46979-ade3-4b75-87f0-edefd43f6c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
