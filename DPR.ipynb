{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering, pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = wikipedia.page(\"Coronavirus\").content\n",
    "london = wikipedia.page(\"London\").content\n",
    "japan = wikipedia.page(\"Japan\").content\n",
    "china = wikipedia.page(\"China\").content\n",
    "football = wikipedia.page(\"football\").content\n",
    "sports = wikipedia.page(\"sports\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\").to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"phiyodr/roberta-large-finetuned-squad2\"\n",
    "\n",
    "tokenizer_ans = AutoTokenizer.from_pretrained(model_name)\n",
    "model_ans = AutoModelForQuestionAnswering.from_pretrained(model_name).eval()\n",
    "pipe = pipeline(\"question-answering\",model_ans,tokenizer =tokenizer_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_top_answers(possible_starts,possible_ends,input_ids):\\n    answers = []\\n    for start,end in zip(possible_starts,possible_ends):\\n        answer = tokenizer_ans.convert_tokens_to_string(tokenizer_ans.convert_ids_to_tokens(input_ids[start:end+1]))\\n        answers.append(answer)\\n    return answers  \\n\\ndef answer_that(query, passage, n_answers=2):  \\n    \\n    inputs = tokenizer_ans.encode_plus(query, passage, add_special_tokens=True, return_tensors=\"pt\")\\n    \\n    outputs = model_ans(**inputs)\\n    \\n    start_scores = outputs.start_logits\\n    end_scores = outputs.end_logits\\n    \\n    possible_starts = np.argsort(start_scores.cpu().detach().numpy()).flatten()[::-1][:n_answers]\\n    possible_ends = np.argsort(end_scores.cpu().detach().numpy()).flatten()[::-1][:n_answers]\\n   \\n    answer_start = torch.argmax(start_scores)  \\n    answer_end = torch.argmax(end_scores) + 1  \\n    \\n    input_ids = inputs[\"input_ids\"].tolist()[0]\\n    answer = tokenizer_ans.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\\n    answers = get_top_answers(possible_starts,possible_ends,input_ids)\\n    return answers\\n\\n%%time\\nprobs = softmax(sorted(scores,reverse = True))\\nfor i,(passage,_) in enumerate(doc_score_pairs[:5]):\\n    try:\\n        print(\"Passage probability is:\",probs[i])\\n        print(answer_that(query,passage,n_answers=1))\\n        \\n    except Exception as e:\\n        print(e)\\n        break'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_top_answers(possible_starts,possible_ends,input_ids):\n",
    "    answers = []\n",
    "    for start,end in zip(possible_starts,possible_ends):\n",
    "        answer = tokenizer_ans.convert_tokens_to_string(tokenizer_ans.convert_ids_to_tokens(input_ids[start:end+1]))\n",
    "        answers.append(answer)\n",
    "    return answers  \n",
    "\n",
    "def answer_that(query, passage, n_answers=2):  \n",
    "    \n",
    "    inputs = tokenizer_ans.encode_plus(query, passage, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    \n",
    "    outputs = model_ans(**inputs)\n",
    "    \n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "    \n",
    "    possible_starts = np.argsort(start_scores.cpu().detach().numpy()).flatten()[::-1][:n_answers]\n",
    "    possible_ends = np.argsort(end_scores.cpu().detach().numpy()).flatten()[::-1][:n_answers]\n",
    "   \n",
    "    answer_start = torch.argmax(start_scores)  \n",
    "    answer_end = torch.argmax(end_scores) + 1  \n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    answer = tokenizer_ans.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    answers = get_top_answers(possible_starts,possible_ends,input_ids)\n",
    "    return answers\n",
    "\n",
    "%%time\n",
    "probs = softmax(sorted(scores,reverse = True))\n",
    "for i,(passage,_) in enumerate(doc_score_pairs[:5]):\n",
    "    try:\n",
    "        print(\"Passage probability is:\",probs[i])\n",
    "        print(answer_that(query,passage,n_answers=1))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:,0]\n",
    "\n",
    "def encode_query(query):\n",
    "    encoded_input = tokenizer(query, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    embeddings = cls_pooling(model_output)\n",
    "\n",
    "    return embeddings.to(torch.float16)\n",
    "\n",
    "\n",
    "def encode_docs(docs,maxlen = 64, stride = 32):\n",
    "    encoded_input = []\n",
    "    embeddings = []\n",
    "    spans = []\n",
    "    labels = []\n",
    "    label = 0\n",
    "    \n",
    "    for text in tqdm(docs):\n",
    "        text = text.split(\" \")\n",
    "        if len(text) < maxlen:\n",
    "            text = \" \".join(text)\n",
    "            encoded_input.append(tokenizer(text,  return_tensors='pt', truncation = True).to(device))\n",
    "            spans.append(text)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            num_iters = int(len(text)/maxlen)\n",
    "            for i in range(num_iters):\n",
    "                if i == 0:\n",
    "                    temp_text = \" \".join(text[i*maxlen:(i+1)*maxlen+stride])\n",
    "                else:\n",
    "                    temp_text = \" \".join(text[(i-1)*maxlen:(i)*maxlen][-stride:] + text[i*maxlen:(i+1)*maxlen])\n",
    "                \n",
    "                encoded_input.append(tokenizer(temp_text, return_tensors='pt', truncation = True).to(device))\n",
    "                spans.append(temp_text)\n",
    "                labels.append(label)\n",
    "        label+=1\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for encoded in tqdm(encoded_input):\n",
    "            model_output = model(**encoded, return_dict=True)\n",
    "            embeddings.append(cls_pooling(model_output))\n",
    "\n",
    "    return np.float32(torch.stack(embeddings).transpose(0, 1).cpu().detach()), spans, encoded_input, labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 11.79it/s]\n",
      "100%|██████████| 856/856 [00:09<00:00, 88.71it/s]\n"
     ]
    }
   ],
   "source": [
    "if 'emb.npy' in os.listdir():\n",
    "    emb_dicto = np.load('emb.npy',allow_pickle='TRUE').item()\n",
    "    res_dicto = np.load('spans.npy',allow_pickle='TRUE').item()\n",
    "    doc_emb = np.array(list(emb_dicto.values()))\n",
    "    doc_text = list(res_dicto.values())\n",
    "else:\n",
    "    docs = [london, covid, japan, china, football, sports]\n",
    "    doc_emb, doc_text,encoded_input, labels = encode_docs(docs)\n",
    "    np.save('emb.npy',dict(zip(list(range(len(doc_emb))),doc_emb))) \n",
    "    np.save('spans.npy',dict(zip(list(range(len(doc_text))),doc_text))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22.933631896972656 \n",
      " people in 2011, while its wider metropolitan area had a population of 12–14 million, depending on the definition used. According to Eurostat, London is the second most populous metropolitan area in Europe. A net 726,000 immigrants arrived there in the period 1991–2001.The region covers 1,579 square kilometres (610 sq mi), giving a population density of 5,177 inhabitants per square kilometre (13,410/sq mi), more than ten times that of any other British region. In population terms, London is the 19th largest city and the 18th largest metropolitan region.\n",
      "\n",
      "\n",
      "=== Age structure and median age ===\n",
      "Children younger than 14\n",
      "\n",
      "22.107393264770508 \n",
      " into residential areas at night to take advantage of London's green spaces.\n",
      "\n",
      "\n",
      "== Demography ==\n",
      "\n",
      "The 2011 census recorded that 2,998,264 people or 36.7% of London's population were foreign-born making it the city with the second largest immigrant population after New York, in terms of absolute numbers. About 69% of children born in London in 2015 had at least one parent who was born abroad. The table to the right shows the commonest countries of birth of London residents. Note that some of the German-born population, in 18th position, are British citizens from birth born to parents serving\n",
      "\n",
      "21.97740936279297 \n",
      " encompasses a total area of 1,583 square kilometres (611 sq mi), an area which had a population of 7,172,036 in 2001 and a population density of 4,542 inhabitants per square kilometre (11,760/sq mi). The extended area known as the London Metropolitan Region or the London Metropolitan Agglomeration, comprises a total area of 8,382 square kilometres (3,236 sq mi) has a population of 13,709,000 and a population density of 1,510 inhabitants per square kilometre (3,900/sq mi). Modern London stands on the Thames, its primary geographical feature, a navigable river which crosses the city from the south-west to\n",
      "\n",
      "21.89035415649414 \n",
      " the most populous city in the world. It peaked at 8,615,245 in 1939, just before the outbreak of the Second World War, but had declined to 7,192,091 by the 2001 Census. However, the population then grew by just over a million between the 2001 and 2011 Censuses, to reach 8,173,941 in the latter.However, London's continuous urban area extends beyond Greater London and numbered 9,787,426 people in 2011, while its wider metropolitan area had a population of 12–14 million, depending on the definition used. According to Eurostat, London is the second most populous metropolitan area in Europe.\n",
      "\n",
      "21.18191909790039 \n",
      " city. It accounts for 13.4 per cent of the UK population. Greater London Built-up Area is the fourth-most populous in Europe, after Istanbul, Moscow and Paris, with 9,787,426 inhabitants at the 2011 census. The London metropolitan area is the third-most populous in Europe after Istanbul's and Moscow's, with 14,040,163 inhabitants in 2016.\n",
      "London has four World Heritage Sites: the Tower of London; Kew Gardens; the Palace of Westminster, along with  Westminster Abbey, and St Margaret's Church; and the historic settlement in Greenwich, where the Royal Observatory, Greenwich defines the Prime Meridian (0° longitude) and Greenwich Mean\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#query = \"What is one child policy?\"\n",
    "#query = \"How many Summer Games has London hosted?\"\n",
    "#query = \"What is the current population of China?\"\n",
    "query = \"How many people live in London?\"\n",
    "#query = \"What is the population of London?\"\n",
    "#query = \"What is the highest mountain?\"\n",
    "query_emb = encode_query(query).cpu()\n",
    "\n",
    "scores = np.matmul(query_emb, doc_emb.reshape(-1,768).transpose(1,0))[0].tolist()\n",
    "doc_score_pairs = list(zip(doc_text, scores))\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for doc, score in doc_score_pairs[:5]:\n",
    "    print()\n",
    "    print(score, \"\\n\",doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(answer|query,passage): 1.7910067202462876e-06, P(passage|query): 0.42592900637915004\n",
      "Answer: 12–14 million, P(answer|passage): 4.204941888019675e-06\n",
      "\n",
      "P(answer|query,passage): 0.00011236944825303919, P(passage|query): 0.18642593866291862\n",
      "Answer: 36.7% of London's population were foreign-born P(answer|passage): 0.0006027565104886889\n",
      "\n",
      "P(answer|query,passage): 0.09802841292079759, P(passage|query): 0.1637024002086898\n",
      "Answer: 7,172,036 P(answer|passage): 0.5988208651542664\n",
      "\n",
      "P(answer|query,passage): 2.53292467022337e-06, P(passage|query): 0.15005395661924167\n",
      "Answer: 8,173,941 P(answer|passage): 1.6880092516657896e-05\n",
      "\n",
      "P(answer|query,passage): 0.002450631556800161, P(passage|query): 0.0738886981299984\n",
      "Answer: 14,040,163 P(answer|passage): 0.03316652774810791\n",
      "\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 5\n",
    "probs = softmax(sorted(scores,reverse = True)[:k])\n",
    "for i, (passage, _) in enumerate(doc_score_pairs[:k]):\n",
    "    ans = pipe(query, passage)\n",
    "    print(\"P(answer|query,passage): {}, P(passage|query): {}\".format(ans[\"score\"]*probs[i],probs[i]))\n",
    "    print(\"Answer:\", ans[\"answer\"], \"P(answer|passage):\",ans[\"score\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 75.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(634, 14.96799)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "best = 0\n",
    "best_i = 0\n",
    "doc_T = doc_emb.reshape(-1,768).transpose(1,0)\n",
    "doc_r = doc_emb.reshape(-1,768)\n",
    "for i in range(doc_T.shape[1]):\n",
    "    candidate = np.mean(np.matmul(doc_r[i,:], doc_T))\n",
    "    if candidate > best:\n",
    "        best = candidate\n",
    "        best_i = i\n",
    "best_i,best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=int(np.sqrt(doc_emb.shape[0])), random_state=0).fit(doc_emb.cpu().view(-1,768))\n",
    "for i,n in enumerate(kmeans.predict(doc_emb.cpu().view(-1,768))):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
